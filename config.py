# Paper: In the training phase, we set the batch size to 128,
# base learning rate to 10−3, weight decay to 5×10−4, and momentum to 0.9

lr = 1e-3
decay = 5e-4
momentum = 0.9
batch_size = 128
epochs = 20
n_classes = 31
lambda_coral = 0
